{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "config = botocore.config.Config(\n",
    "    read_timeout=900,\n",
    "    connect_timeout=900,\n",
    "    retries={\"max_attempts\": 0}\n",
    ")\n",
    "\n",
    "bedrock_client = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    r\"C:\\Users\\Lenovo\\Documents\\Project-vs code\\Amazon Transcribe\\mahendhra\\man\"\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "embeddings = BedrockEmbeddings(model_id=\"cohere.embed-multilingual-v3\")\n",
    "\n",
    "CONNECTION_STRING = \"postgresql+psycopg2://postgres:serverless123@database-1-instance-1.cxbpo87iqdgv.us-east-1.rds.amazonaws.com:5432/database1\"\n",
    "\n",
    "COLLECTION_NAME = \"mahendhra\"\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=texts,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    pre_delete_collection= False\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    Generate answers truthfully based only on the given document\n",
    "    1.Must identify the language of user's question\n",
    "    2.Must Give the response only in identified user's language in question\n",
    "    3.Analyse all the text datas and generate accurate answers\n",
    "\n",
    "for example:\n",
    "1.if the asked question is tamil language you should give the response in the tamil language only.\n",
    "\n",
    "\n",
    "{context}\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type='similarity', search_kwargs={\"k\": 3})\n",
    "llm = Bedrock(model_id=\"anthropic.claude-v2:1\",client=bedrock_client,model_kwargs = {\"temperature\":1e-10,\"max_tokens_to_sample\": 20000})\n",
    "qa_prompt = PromptTemplate(template=template, input_variables=[\"context\",\"question\"])\n",
    "chain_type_kwargs = { \"prompt\": qa_prompt, \"verbose\": False }\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is the quantity of oil in the Transaxel\"\n",
    "result = qa.run(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 81\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Wait for all the embeddings to be calculated\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m embeddings_future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(embeddings_futures):\n\u001b[1;32m---> 81\u001b[0m     embeddings_list\u001b[38;5;241m.\u001b[39mappend(embeddings_future\u001b[38;5;241m.\u001b[39mresult())\n\u001b[0;32m     83\u001b[0m     db \u001b[38;5;241m=\u001b[39m PGVector\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[0;32m     84\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m     85\u001b[0m     documents\u001b[38;5;241m=\u001b[39membeddings_list,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     88\u001b[0m     pre_delete_collection\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[1;32mIn[7], line 69\u001b[0m, in \u001b[0;36msplit_and_embed\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_and_embed\u001b[39m(doc):\n\u001b[0;32m     68\u001b[0m     texts \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents([doc])\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39membed_documents(texts)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\bedrock.py:169\u001b[0m, in \u001b[0;36mBedrockEmbeddings.embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    167\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[1;32m--> 169\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_func(text)\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize:\n\u001b[0;32m    172\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_vector(response)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\bedrock.py:118\u001b[0m, in \u001b[0;36mBedrockEmbeddings._embedding_func\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call out to Bedrock embedding endpoint.\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# replace newlines, which can negatively affect performance.\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(os\u001b[38;5;241m.\u001b[39mlinesep, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# format input body for provider\u001b[39;00m\n\u001b[0;32m    121\u001b[0m provider \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Document' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import boto3\n",
    "import botocore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "config = botocore.config.Config(\n",
    "    read_timeout=900,\n",
    "    connect_timeout=900,\n",
    "    retries={\"max_attempts\": 0}\n",
    ")\n",
    "\n",
    "bedrock_client = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "CONNECTION_STRING = \"postgresql+psycopg2://postgres:serverless123@database-1-instance-1.cxbpo87iqdgv.us-east-1.rds.amazonaws.com:5432/database1\"\n",
    "\n",
    "COLLECTION_NAME = \"mahendhra_rise1\"\n",
    "\n",
    "loader = PyPDFLoader(\n",
    "    r\"C:\\Users\\Lenovo\\Documents\\Project-vs code\\Amazon Transcribe\\mahendhra\\MAN01074RepairManualXUV700DieselATRev1.pdf\"\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You will be given a query, Your task is to find an answer or give information about the query with respect to the document by performing a similarity search.\n",
    "    Consider the following conditions,\n",
    "    - If query is a topic, look for information or statements or sentences which are related to the query in the document.\n",
    "    - The answer does not need to be specifically related, it can be loosely related as well.\n",
    "    - If you find any statements that are directly related to the query, then explain those statements in easy or layman terms, so someone with no expertise in that field can understand.\n",
    "    - If query is a question, understand the context of query and then look for similar statements or sentences in the document which also have the same context.\n",
    "    - It is not necessary to return direct statements from the document as an answer. You can also return loosely related answers to the query.\n",
    "    - If you cannot find any direct statements or directly relevant answers, do not return that you cannot find any direct statements. Then, you have to perform a semantic search instead of looking for exact words in the document, that is, understanding the context from the query and looking for something similar in the document.\n",
    "    - It is not mandatory to look for direct statements, you can also look at statements with a similar meaning and context.\n",
    "    - It is fine if you cannot find any directly related statements in the document. You can look for sentences with similar meaning and can also return loosely related answers.\n",
    "    - Elaborate the answer as much as you can.\n",
    "    - If the table datas are there must extract and give the accurate answers\n",
    "    - If you cannot find a relevant answer, then perform a similarity search on all statements which have a similar meaning to the query, and the document.\n",
    "    - If even after doing the search on similar statements, you can't find an answer, you can just say that you are not able to find any answer without saying anything else.\n",
    "    - The output should just be a bullet list of points which has the summary of all points obtained from the search and nothing else. Do not say anything like you have or haven't found directly related answers.\n",
    "    - Please refrain from returning the process or steps followed to obtain the answer, you can only return the answers which are closely or loosely related to the query and do not return anything else.\n",
    "    - If is English: Return the answer obtained as the output.\n",
    "    - Else: translate the answer obtained when performing a similarity search into and then return as output.\n",
    "    - Do not return anything other than the bullet list of points.\n",
    "\n",
    "\n",
    "{context}\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# Create a TextSplitter object\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=0)\n",
    "\n",
    "# Create an Embeddings object\n",
    "embeddings = BedrockEmbeddings(model_id=\"cohere.embed-multilingual-v3\")\n",
    "\n",
    "# Define a function to split and embed a document\n",
    "def split_and_embed(doc):\n",
    "    texts = text_splitter.split_documents([doc])\n",
    "    return embeddings.embed_documents(texts)\n",
    "\n",
    "# Create a list of documents\n",
    "docs = loader.load()\n",
    "\n",
    "# Create a ThreadPoolExecutor\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Use the executor to run the split_and_embed function on all documents\n",
    "    embeddings_futures = [executor.submit(split_and_embed, doc) for doc in docs]\n",
    "    for doc in docs:\n",
    "    doc_str = doc.page_content\n",
    "    doc_str = doc_str.replace(\"old_text\", \"new_text\")\n",
    "    doc.page_content = doc_str\n",
    "\n",
    "    embeddings_list = []\n",
    "    # Wait for all the embeddings to be calculated\n",
    "    for embeddings_future in concurrent.futures.as_completed(embeddings_futures):\n",
    "        embeddings_list.append(embeddings_future.result())\n",
    "\n",
    "        db = PGVector.from_documents(\n",
    "        embedding=embeddings,\n",
    "        documents=embeddings_list,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        connection_string=CONNECTION_STRING,\n",
    "        pre_delete_collection= False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type='similarity', search_kwargs={\"k\": 3})\n",
    "llm = Bedrock(model_id=\"anthropic.claude-v2:1\",client=bedrock_client,model_kwargs = {\"temperature\":1e-10,\"max_tokens_to_sample\": 20000})\n",
    "qa_prompt = PromptTemplate(template=template, input_variables=[\"context\",\"question\"])\n",
    "chain_type_kwargs = { \"prompt\": qa_prompt, \"verbose\": False }\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is the quantity of oil in the Transaxel\"\n",
    "result = qa.run(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 81\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Wait for all the embeddings to be calculated\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m embeddings_future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(embeddings_futures):\n\u001b[1;32m---> 81\u001b[0m     embeddings_list\u001b[38;5;241m.\u001b[39mappend(embeddings_future\u001b[38;5;241m.\u001b[39mresult())\n\u001b[0;32m     83\u001b[0m     db \u001b[38;5;241m=\u001b[39m PGVector\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[0;32m     84\u001b[0m         embedding\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m     85\u001b[0m         documents\u001b[38;5;241m=\u001b[39membeddings_list,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     88\u001b[0m         pre_delete_collection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[1;32mIn[8], line 68\u001b[0m, in \u001b[0;36msplit_and_embed\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_and_embed\u001b[39m(doc):\n\u001b[1;32m---> 68\u001b[0m     texts \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents([doc\u001b[38;5;241m.\u001b[39mpage_content])  \u001b[38;5;66;03m# Convert Document object to string\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39membed_documents(texts)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\langchain_text_splitters\\base.py:93\u001b[0m, in \u001b[0;36mTextSplitter.split_documents\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m     91\u001b[0m texts, metadatas \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[1;32m---> 93\u001b[0m     texts\u001b[38;5;241m.\u001b[39mappend(doc\u001b[38;5;241m.\u001b[39mpage_content)\n\u001b[0;32m     94\u001b[0m     metadatas\u001b[38;5;241m.\u001b[39mappend(doc\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_documents(texts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import boto3\n",
    "import botocore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "config = botocore.config.Config(\n",
    "    read_timeout=900,\n",
    "    connect_timeout=900,\n",
    "    retries={\"max_attempts\": 0}\n",
    ")\n",
    "\n",
    "bedrock_client = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "CONNECTION_STRING = \"postgresql+psycopg2://postgres:serverless123@database-1-instance-1.cxbpo87iqdgv.us-east-1.rds.amazonaws.com:5432/database1\"\n",
    "\n",
    "COLLECTION_NAME = \"mahendhra_rise1\"\n",
    "\n",
    "loader = PyPDFLoader(\n",
    "    r\"C:\\Users\\Lenovo\\Documents\\Project-vs code\\Amazon Transcribe\\mahendhra\\MAN01074RepairManualXUV700DieselATRev1.pdf\"\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You will be given a query, Your task is to find an answer or give information about the query with respect to the document by performing a similarity search.\n",
    "    Consider the following conditions,\n",
    "    - If query is a topic, look for information or statements or sentences which are related to the query in the document.\n",
    "    - The answer does not need to be specifically related, it can be loosely related as well.\n",
    "    - If you find any statements that are directly related to the query, then explain those statements in easy or layman terms, so someone with no expertise in that field can understand.\n",
    "    - If query is a question, understand the context of query and then look for similar statements or sentences in the document which also have the same context.\n",
    "    - It is not necessary to return direct statements from the document as an answer. You can also return loosely related answers to the query.\n",
    "    - If you cannot find any direct statements or directly relevant answers, do not return that you cannot find any direct statements. Then, you have to perform a semantic search instead of looking for exact words in the document, that is, understanding the context from the query and looking for something similar in the document.\n",
    "    - It is not mandatory to look for direct statements, you can also look at statements with a similar meaning and context.\n",
    "    - It is fine if you cannot find any directly related statements in the document. You can look for sentences with similar meaning and can also return loosely related answers.\n",
    "    - Elaborate the answer as much as you can.\n",
    "    - If the table datas are there must extract and give the accurate answers\n",
    "    - If you cannot find a relevant answer, then perform a similarity search on all statements which have a similar meaning to the query, and the document.\n",
    "    - If even after doing the search on similar statements, you can't find an answer, you can just say that you are not able to find any answer without saying anything else.\n",
    "    - The output should just be a bullet list of points which has the summary of all points obtained from the search and nothing else. Do not say anything like you have or haven't found directly related answers.\n",
    "    - Please refrain from returning the process or steps followed to obtain the answer, you can only return the answers which are closely or loosely related to the query and do not return anything else.\n",
    "    - If is English: Return the answer obtained as the output.\n",
    "    - Else: translate the answer obtained when performing a similarity search into and then return as output.\n",
    "    - Do not return anything other than the bullet list of points.\n",
    "\n",
    "\n",
    "{context}\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# Create a TextSplitter object\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "\n",
    "# Create an Embeddings object\n",
    "embeddings = BedrockEmbeddings(model_id=\"cohere.embed-multilingual-v3\")\n",
    "\n",
    "# Define a function to split and embed a document\n",
    "def split_and_embed(doc):\n",
    "    texts = text_splitter.split_documents([doc.page_content])  # Convert Document object to string\n",
    "    return embeddings.embed_documents(texts)\n",
    "\n",
    "# Create a list of documents\n",
    "docs = loader.load()\n",
    "\n",
    "# Create a ThreadPoolExecutor\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Use the executor to run the split_and_embed function on all documents\n",
    "    embeddings_futures = [executor.submit(split_and_embed, doc) for doc in docs]\n",
    "    embeddings_list = []\n",
    "    # Wait for all the embeddings to be calculated\n",
    "    for embeddings_future in concurrent.futures.as_completed(embeddings_futures):\n",
    "        embeddings_list.append(embeddings_future.result())\n",
    "\n",
    "        db = PGVector.from_documents(\n",
    "            embedding=embeddings,\n",
    "            documents=embeddings_list,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            connection_string=CONNECTION_STRING,\n",
    "            pre_delete_collection=False\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
