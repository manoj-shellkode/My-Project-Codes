{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF created and uploaded for Screenshot (5).png as Screenshot (5).pdf\n",
      "Waiting for My-transcription_mp3_1701157072_0. Current status is IN_PROGRESS.\n",
      "Waiting for My-transcription_mp3_1701157072_0. Current status is IN_PROGRESS.\n",
      "Job My-transcription_mp3_1701157072_0 is COMPLETED.\n",
      "Waiting for My-transcription_mp4_1701157100_0. Current status is IN_PROGRESS.\n",
      "Waiting for My-transcription_mp4_1701157100_0. Current status is IN_PROGRESS.\n",
      "Job My-transcription_mp4_1701157100_0 is COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from io import BytesIO\n",
    "import time\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.document_loaders import S3FileLoader\n",
    "from bedrock import get_bedrock_client\n",
    "import os\n",
    "import time\n",
    "import urllib\n",
    "import json\n",
    "bucket_name = 'my-s3-doc-loader'\n",
    "\n",
    "# Function from the first code\n",
    "def transcribe_and_create_pdf(language_code='en-US',\n",
    "                               job_name_prefix='My-transcription', pdf_filename_prefix='Transcription_output'):\n",
    "    transcribe_client = boto3.client('transcribe')\n",
    "\n",
    "    def transcribe_file(job_name, file_uri, transcribe_client, media_format, language_code):\n",
    "        transcribe_client.start_transcription_job(\n",
    "            TranscriptionJobName=job_name,\n",
    "            Media={'MediaFileUri': file_uri},\n",
    "            MediaFormat=media_format,\n",
    "            LanguageCode=language_code\n",
    "        )\n",
    "        max_tries = 60\n",
    "        while max_tries > 0:\n",
    "            max_tries -= 1\n",
    "            job = transcribe_client.get_transcription_job(TranscriptionJobName=job_name)\n",
    "            job_status = job['TranscriptionJob']['TranscriptionJobStatus']\n",
    "            if job_status in ['COMPLETED', 'FAILED']:\n",
    "                print(f\"Job {job_name} is {job_status}.\")\n",
    "                if job_status == 'COMPLETED':\n",
    "                    response = urllib.request.urlopen(job['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "                    data = json.loads(response.read())\n",
    "                    text = data['results']['transcripts'][0]['transcript']\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Waiting for {job_name}. Current status is {job_status}.\")\n",
    "            time.sleep(10)\n",
    "        return text\n",
    "\n",
    "    def process_media_format(media_format, s3_bucket_name):\n",
    "        timestamp = str(int(time.time()))\n",
    "        job_name = f'{job_name_prefix}_{media_format}_{timestamp}'\n",
    "\n",
    "        s3_client = boto3.client('s3')\n",
    "        s3_objects = s3_client.list_objects(Bucket=s3_bucket_name)\n",
    "\n",
    "        file_uris = []\n",
    "        for obj in s3_objects.get('Contents', []):\n",
    "            if obj['Key'].lower().endswith(f'.{media_format}'):\n",
    "                file_uris.append(f's3://{s3_bucket_name}/{obj[\"Key\"]}')\n",
    "\n",
    "        if not file_uris:\n",
    "            return \"\", []\n",
    "\n",
    "        transcribed_text = \"\"\n",
    "        s3_uris = []  # Store the S3 URIs for all processed files\n",
    "        for i, file_uri in enumerate(file_uris):\n",
    "            text = transcribe_file(f\"{job_name}_{i}\", file_uri, transcribe_client, media_format, language_code)\n",
    "            transcribed_text += f\"Transcribed Text ({media_format.upper()}) - File {i + 1}:\\n{text}\\n\\n\"\n",
    "\n",
    "            # Create PDF in memory\n",
    "            pdf_buffer = BytesIO()\n",
    "            pdf = canvas.Canvas(pdf_buffer)\n",
    "            pdf.setFont(\"Helvetica\", 12)\n",
    "            pdf.drawString(10, 800, f\"Transcribed Text ({media_format.upper()}) - File {i + 1}:\")\n",
    "            text_lines = text.split('\\n')\n",
    "            for j, line in enumerate(text_lines):\n",
    "                pdf.drawString(10, 780 - j * 15, line)\n",
    "            pdf.save()\n",
    "\n",
    "            # Upload PDFs to S3 with unique filenames\n",
    "            pdf_filename = f'{pdf_filename_prefix}_{media_format}_{timestamp}_file_{i + 1}.pdf'\n",
    "            s3_key = pdf_filename\n",
    "\n",
    "            # Reset the buffer position to the beginning\n",
    "            pdf_buffer.seek(0)\n",
    "\n",
    "            # Upload the PDF directly from the in-memory buffer\n",
    "            s3_client.upload_fileobj(pdf_buffer, s3_bucket_name, s3_key)\n",
    "\n",
    "            # Append the S3 URI to the list\n",
    "            s3_uris.append(f's3://{s3_bucket_name}/{s3_key}')\n",
    "\n",
    "        return transcribed_text, s3_uris\n",
    "\n",
    "    s3_bucket_name = 'my-s3-doc-loader'\n",
    "\n",
    "    # Process MP3 files\n",
    "    transcribed_text_mp3, s3_uris_mp3 = process_media_format('mp3', s3_bucket_name)\n",
    "\n",
    "    # Process MP4 files\n",
    "    transcribed_text_mp4, s3_uris_mp4 = process_media_format('mp4', s3_bucket_name)\n",
    "\n",
    "    return transcribed_text_mp3, s3_uris_mp3, transcribed_text_mp4, s3_uris_mp4\n",
    "\n",
    "# Call the function and get the transcribed text and S3 URIs for both MP3 and MP4\n",
    "#transcribed_text_mp3, s3_uris_mp3, transcribed_text_mp4, s3_uris_mp4 = transcribe_and_create_pdf()\n",
    "\n",
    "\n",
    "# Function from the second code\n",
    "def process_images_and_create_pdf(bucket_name):\n",
    "    bucket_name = 'my-s3-doc-loader'\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "files_to_process = [obj['Key'] for obj in response.get('Contents', []) if obj['Key'].lower().endswith(('.png', '.jpeg'))]\n",
    "\n",
    "# Step 2: Process each file\n",
    "for file_name in files_to_process:\n",
    "    # Amazon Textract client\n",
    "    textract = boto3.client('textract')\n",
    "\n",
    "    # Call Textract to detect text\n",
    "    response = textract.detect_document_text(\n",
    "        Document={\n",
    "            'S3Object': {\n",
    "                'Bucket': bucket_name,\n",
    "                'Name': file_name\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    lines = []\n",
    "    for item in response[\"Blocks\"]:\n",
    "        if item[\"BlockType\"] == \"LINE\":\n",
    "            lines.append(item[\"Text\"])\n",
    "    \n",
    "    result = '\\n'.join(lines)\n",
    "\n",
    "    # Create a PDF\n",
    "    pdf_buffer = BytesIO()\n",
    "    pdf = canvas.Canvas(pdf_buffer, pagesize=letter)\n",
    "    pdf.setFont(\"Helvetica\", 12)\n",
    "    \n",
    "    # Adjust the coordinates as needed\n",
    "    text_lines = result.split('\\n')\n",
    "    for j, line in enumerate(text_lines):\n",
    "        pdf.drawString(10, 780 - j * 15, line)\n",
    "\n",
    "    pdf.save()\n",
    "    pdf_buffer.seek(0)\n",
    "\n",
    "    # Upload the PDF to S3\n",
    "    pdf_key = f\"{file_name.split('.')[0]}.pdf\"  # Assuming you want to use the same file name with a '.pdf' extension\n",
    "    s3.upload_fileobj(pdf_buffer, bucket_name, pdf_key)\n",
    "\n",
    "    # Optionally, you can print a message indicating that the PDF has been uploaded\n",
    "    print(f\"PDF created and uploaded for {file_name} as {pdf_key}\")\n",
    "\n",
    "\n",
    "\n",
    "# Main logic to determine which code to execute based on file formats in the S3 bucket\n",
    "\n",
    "s3_bucket_name = 'my-s3-doc-loader'\n",
    "    \n",
    "response = boto3.client('s3').list_objects_v2(Bucket=s3_bucket_name)\n",
    "file_names = [obj['Key'] for obj in response.get('Contents', [])]\n",
    "\n",
    "mp3_mp4_formats = any(file_name.lower().endswith(('.mp3', '.mp4')) for file_name in file_names)\n",
    "image_formats = any(file_name.lower().endswith(('.png', '.jpeg')) for file_name in file_names)\n",
    "\n",
    "if mp3_mp4_formats:\n",
    "    transcribed_text_mp3, s3_uris_mp3, transcribed_text_mp4, s3_uris_mp4 = transcribe_and_create_pdf()\n",
    "\n",
    "if image_formats:\n",
    "    process_images_and_create_pdf(s3_bucket_name)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_formats = ['.pdf', '.doc', '.txt', '.docx']\n",
    "s3 = boto3.client('s3')\n",
    "response = s3.list_objects(Bucket=s3_bucket_name)\n",
    "file_keys = [obj['Key'] for obj in response.get('Contents', []) if any(obj['Key'].endswith(format) for format in file_formats)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_contents = []\n",
    "# for key in file_keys:\n",
    "#     loader = S3FileLoader(bucket=s3_bucket_name, key=key)\n",
    "#     context_content = loader.load()\n",
    "#     context_contents.append(context_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_content = \"\"\n",
    "# for key in file_keys:\n",
    "#     loader = S3FileLoader(bucket=s3_bucket_name, key=key)\n",
    "#     context_content = loader.load()\n",
    "#     context_content = [str(item) for item in context_content]\n",
    "#     combined_content += '\\n'.join(context_content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, page_content, metadata=None):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata if metadata is not None else {}\n",
    "\n",
    "\n",
    "\n",
    "combined_content = \"\"\n",
    "\n",
    "for key in file_keys:\n",
    "    loader = S3FileLoader(bucket=s3_bucket_name, key=key)\n",
    "    context_content = loader.load()\n",
    "    context_content = [str(item) for item in context_content]\n",
    "    combined_content += '\\n'.join(context_content)\n",
    "\n",
    "# Assuming you have a Document class with both page_content and metadata attributes\n",
    "documents_list = [Document(page_content=combined_content)]\n",
    "\n",
    "# Now use the text_splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000)\n",
    "context_texts = text_splitter.split_documents(documents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000)\n",
    "# context_texts = text_splitter.split_documents(combined_content)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = FAISS.from_documents(documents=context_texts, embedding=embeddings)\n",
    "\n",
    "retriever = db.as_retriever(search_type='mmr', search_kwargs={\"k\": 3})\n",
    "\n",
    "template = \"\"\"\n",
    "Human: Answer truthfully based on the given question, fetch the answer only from the given text documents\n",
    "Instruction:\n",
    "1. If multiple files are there, read all the files each and every line accurately to generate the answer.\n",
    "2. If there is no text found in the text document about the asked question, print \"no result found.\" Do not print any results if the answer is not found; do not search the answers from outside.\n",
    "3. Generate an answer whatever is available related to the question.\n",
    "4. Must complete the sentence in the result fully; do not leave results incomplete format in the end.\n",
    "text:{context}\n",
    "question:{question}\n",
    "Assistant:\"\"\"\n",
    "bedrock_client = get_bedrock_client(region='us-east-1', runtime=True)\n",
    "qa_prompt = PromptTemplate(template=template, input_variables=[\"context\",\"question\"])\n",
    "chain_type_kwargs = {\"prompt\": qa_prompt}\n",
    "llm = Bedrock(model_id=\"anthropic.claude-v2\", client=bedrock_client)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    verbose=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the given text, here is the summary about Azure:\n",
      "\n",
      "Azure is an open and flexible cloud platform by Microsoft for services like analytics, virtual computing, storage, networking, and more. It offers a growing selection of products and services on a single platform to meet various demands. Azure enables cloud computing and is designed to manage tasks through Microsoft's data centers. \n",
      "\n",
      "Some key points about Azure:\n",
      "\n",
      "- It is used by companies like eBay, Boeing, Samsung, BMW etc for their cloud infrastructure needs due to its adaptability. \n",
      "\n",
      "- It builds mission critical solutions to analyze images, comprehend speech, make predictions using data simultaneously i.e. multitasking. \n",
      "\n",
      "- Data like footage, audio etc travels securely to cloud from remote locations and is securely stored. This data can be easily accessed by editors and production members.\n",
      "\n",
      "- It provides efficient and secure workflow as only data relevant to their role is accessible to production members.\n",
      "\n",
      "- Costs are controllable as users only pay for what they use. Data stored in cloud is accessible globally.\n",
      "\n",
      "- It enables real-time collaboration for reviewing, approving and making changes. Video indexing makes content searchable.\n",
      "\n",
      "- Predictive analytics improves marketing and distribution strategies. Analysis of\n"
     ]
    }
   ],
   "source": [
    "question=\"Explain about azure\"\n",
    "result = qa.run(question)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
