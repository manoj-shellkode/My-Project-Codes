{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import urllib\n",
    "import json\n",
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "transcribe_client = boto3.client('transcribe')\n",
    "from bedrock import get_bedrock_client\n",
    "bedrock_client = get_bedrock_client(region='us-east-1', runtime=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_file(job_name, file_uri, transcribe_client):\n",
    "    transcribe_client.start_transcription_job(\n",
    "        TranscriptionJobName=job_name,\n",
    "        Media={'MediaFileUri': file_uri},\n",
    "        MediaFormat='mp4',\n",
    "        LanguageCode='en-US'\n",
    "    )\n",
    "    max_tries = 60\n",
    "    while max_tries > 0:\n",
    "        max_tries -= 1\n",
    "        job = transcribe_client.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        job_status = job['TranscriptionJob']['TranscriptionJobStatus']\n",
    "        if job_status in ['COMPLETED', 'FAILED']:\n",
    "            print(f\"Job {job_name} is {job_status}.\")\n",
    "            if job_status == 'COMPLETED':\n",
    "                response = urllib.request.urlopen(job['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "                data = json.loads(response.read())\n",
    "                text = data['results']['transcripts'][0]['transcript']\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Waiting for {job_name}. Current status is {job_status}.\")\n",
    "        time.sleep(10)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for My-video-to-text. Current status is IN_PROGRESS.\n",
      "Waiting for My-video-to-text. Current status is IN_PROGRESS.\n",
      "Job My-video-to-text is COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "file_uri = 's3://my-s3-doc-loader/aws1.mp4'\n",
    "text = transcribe_file('My-video-to-text', file_uri, transcribe_client)\n",
    "\n",
    "texts = [text]\n",
    "\n",
    "text_splitter = SentenceTransformersTokenTextSplitter(chunk_size=400)\n",
    "texts = text_splitter.create_documents(texts)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = FAISS.from_documents(documents=texts, embedding=embeddings)\n",
    "retriever = db.as_retriever(search_type='mmr', search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Human: Answer the question as truthfully as possible using only the provided text\n",
    "text:{context}\n",
    "question:{question}\n",
    "Assistant:\"\"\"\n",
    "qa_prompt = PromptTemplate(template=template, input_variables=[\"context\",\"question\"])\n",
    "chain_type_kwargs = { \"prompt\": qa_prompt}\n",
    "llm = Bedrock(model_id=\"anthropic.claude-v2\",client=bedrock_client)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the provided text, some key reasons to use AWS are:\n",
      "\n",
      "- It has a comprehensive and broadly adopted cloud platform used by organizations of all types and sizes to lower costs, become more agile, and innovate faster. \n",
      "\n",
      "- It provides on-demand delivery of technology services via the internet with pay-as-you-go pricing, so you only pay for what you use without upfront costs.\n",
      "\n",
      "- It offers more services and features than any other cloud provider, making it faster, easier and more cost effective to move applications to the cloud.\n",
      "\n",
      "- It offers a wide variety of purpose-built databases and the latest technologies to experiment, innovate quickly, and transform businesses. \n",
      "\n",
      "- It has a global network of regions with multiple availability zones for building scalable, fault tolerant, and highly available applications.\n",
      "\n",
      "- It has unmatched experience, operational expertise, and security standards that customers can depend on for important applications.\n",
      "\n",
      "- It has a large partner network, independent software vendors, and customer community across industries.\n",
      "\n",
      "In summary, the key reasons are the comprehensive and flexible services, innovative technologies, global infrastructure, expertise, and ecosystem support that AWS provides.\n"
     ]
    }
   ],
   "source": [
    "question=\"why AWS?\"\n",
    "result = qa.run(question)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
