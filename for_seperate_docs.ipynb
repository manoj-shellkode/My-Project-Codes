{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from reportlab.pdfgen import canvas\n",
    "from langchain.document_loaders import S3FileLoader\n",
    "from bedrock import get_bedrock_client\n",
    "bedrock_client = get_bedrock_client(region='us-east-1', runtime=True)\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'my-s3-doc-loader'\n",
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "file_names = []\n",
    "allowed_formats = ['.txt', '.pdf', '.doc', '.docx']\n",
    "\n",
    "for obj in response['Contents']:\n",
    "    key = obj['Key']\n",
    "    \n",
    "    # Check if the file has an allowed format\n",
    "    if any(key.lower().endswith(format) for format in allowed_formats):\n",
    "        file_names.append(key)\n",
    "\n",
    "for context_key in file_names:\n",
    "    loader = S3FileLoader(bucket=bucket_name, key=context_key)\n",
    "    context_content = loader.load()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000)\n",
    "context_texts = text_splitter.split_documents(context_content)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = FAISS.from_documents(documents=context_texts, embedding=embeddings)\n",
    "\n",
    "retriever = db.as_retriever(search_type='mmr', search_kwargs={\"k\": 5})\n",
    "\n",
    "template = \"\"\"\n",
    "Human: Answer truthfully based on the given question, fetch the answer only from the given text documents\n",
    "Instruction:\n",
    "1.If multiple files are there, read the all the files each and every lines accurately for to generate answer\n",
    "2.If there is no text found in the text document about the asked question ,\"print no result found\" do not print any results if answer not found,do not search the answers from outside\n",
    "3.Generate answer whatever available related to the question\n",
    "4.Must complete the sentence in the result fully, do not leave results incomplete format in the end.\n",
    "text:{context}\n",
    "question:{question}\n",
    "Assistant:\"\"\"\n",
    "qa_prompt = PromptTemplate(template=template, input_variables=[\"context\",\"question\"])\n",
    "chain_type_kwargs = { \"prompt\": qa_prompt}\n",
    "llm = Bedrock(model_id=\"anthropic.claude-v2\",client=bedrock_client)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    verbose=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
