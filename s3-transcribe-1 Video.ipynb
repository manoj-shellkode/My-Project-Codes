{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for My-video-to-text. Current status is IN_PROGRESS.\n",
      "Waiting for My-video-to-text. Current status is IN_PROGRESS.\n",
      "Waiting for My-video-to-text. Current status is IN_PROGRESS.\n",
      "Waiting for My-video-to-text. Current status is IN_PROGRESS.\n",
      "Waiting for My-video-to-text. Current status is IN_PROGRESS.\n",
      "Waiting for My-video-to-text. Current status is IN_PROGRESS.\n",
      "Waiting for My-video-to-text. Current status is IN_PROGRESS.\n",
      "Job My-video-to-text is COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import urllib\n",
    "import json\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from reportlab.pdfgen import canvas\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import S3FileLoader\n",
    "\n",
    "transcribe_client = boto3.client('transcribe')\n",
    "from bedrock import get_bedrock_client\n",
    "bedrock_client = get_bedrock_client(region='us-east-1', runtime=True)\n",
    "\n",
    "def transcribe_file(job_name, file_uri, transcribe_client):\n",
    "    transcribe_client.start_transcription_job(\n",
    "        TranscriptionJobName=job_name,\n",
    "        Media={'MediaFileUri': file_uri},\n",
    "        MediaFormat='mp4',\n",
    "        LanguageCode='en-US'\n",
    "    )\n",
    "    max_tries = 60\n",
    "    while max_tries > 0:\n",
    "        max_tries -= 1\n",
    "        job = transcribe_client.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        job_status = job['TranscriptionJob']['TranscriptionJobStatus']\n",
    "        if job_status in ['COMPLETED', 'FAILED']:\n",
    "            print(f\"Job {job_name} is {job_status}.\")\n",
    "            if job_status == 'COMPLETED':\n",
    "                response = urllib.request.urlopen(job['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "                data = json.loads(response.read())\n",
    "                text = data['results']['transcripts'][0]['transcript']\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Waiting for {job_name}. Current status is {job_status}.\")\n",
    "        time.sleep(10)\n",
    "    return text\n",
    "\n",
    "file_uri = 's3://my-s3-doc-loader/aws1.mp4'\n",
    "text = transcribe_file('My-video-to-text', file_uri, transcribe_client)\n",
    "\n",
    "pdf_filename = 'Video_text_output.pdf'\n",
    "pdf = canvas.Canvas(pdf_filename)\n",
    "\n",
    "pdf.setFont(\"Helvetica\", 12)\n",
    "pdf.drawString(10, 800, \"Transcribed Text:\")\n",
    "text_lines = text.split('\\n')\n",
    "for i, line in enumerate(text_lines):\n",
    "    pdf.drawString(10, 780 - i * 15, line)\n",
    "\n",
    "pdf.save()\n",
    "\n",
    "s3_bucket_name = 'my-s3-doc-loader'\n",
    "s3_key = pdf_filename\n",
    "s3_client = boto3.client('s3')\n",
    "with open(pdf_filename, 'rb') as pdf_file:\n",
    "    s3_client.upload_fileobj(pdf_file, s3_bucket_name, s3_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\onnxruntime\\capi\\_pybind_state.py:26: UserWarning: Please install the 2019 Visual C++ runtime and then try again. If you've installed the runtime in a non-standard location (other than %SystemRoot%\\System32), make sure it can be found by setting the correct path.\n",
      "  warnings.warn(\"Please install the 2019 Visual C++ runtime and then try again. \"\n"
     ]
    }
   ],
   "source": [
    "loader = S3FileLoader(bucket=s3_bucket_name, key=pdf_filename)\n",
    "file_content = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the provided text, some key reasons to use AWS are:\n",
      "\n",
      "- Pay-as-you-go pricing without upfront costs or long-term commitments. You only pay for the services you use.\n",
      "\n",
      "- Access to a wide variety of cloud computing services that can be used to build and run virtually any type of application. \n",
      "\n",
      "- Access to the large AWS partner network of systems integrators, software vendors, and customers across industries. This provides expertise, integrations, and community support.\n",
      "\n",
      "- Operational expertise and experience from AWS to support mission critical, risk sensitive organizations. \n",
      "\n",
      "- Ability to quickly scale, become more agile, and innovate faster using AWS services.\n",
      "\n",
      "- More services and more features within those services compared to other cloud providers.\n",
      "\n",
      "So in summary, the flexibility, breadth of services, ecosystem, expertise, and pay-as-you-go pricing make AWS an attractive cloud computing platform. The text highlights these as key reasons to choose AWS.\n"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.split_documents(file_content)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = FAISS.from_documents(documents=texts, embedding=embeddings)\n",
    "retriever = db.as_retriever(search_type='mmr', search_kwargs={\"k\": 3})\n",
    "template = \"\"\"\n",
    "Human: Answer the question as truthfully as possible using only the provided text\n",
    "text:{context}\n",
    "question:{question}\n",
    "Assistant:\"\"\"\n",
    "qa_prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs = {\"prompt\": qa_prompt}\n",
    "llm = Bedrock(model_id=\"anthropic.claude-v2\", client=bedrock_client)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    verbose=False\n",
    ")\n",
    "question = \"why AWS?\"\n",
    "result = qa.run(question)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
